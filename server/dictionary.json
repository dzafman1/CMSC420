[{"user-data": {"tags": [], "method": "compute-covariance-matrix", "description": "human readable"}, "description": "computes the covariance matrix", "code": ["def compute_covariance_matrix(loaded_dataset, intermediate_df, description, method):\n", "\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport sys\t\n", "\n", "\tdf = loaded_dataset.select_dtypes(include='number')\n", "\n", "\tif df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\t#convert numerical columns in df to matrix representation\n", "\tdf_matrix = df.as_matrix()\n", "\t\t\n", "\tdata = {\"CovMeanDot\":[]}\n", "\tcovariance = np.cov(df_matrix)\n", "\tmean = np.mean(df_matrix, axis=0)\n", "\t# inv = np.linalg.inv(covariance)\n", "\n", "\t#checks if covariance matrix is singular or not\n", "\tif not (np.linalg.cond(covariance) < 1/sys.float_info.epsilon):\n", "    \t#handle it\n", "\t\tres = {\n", "\t\t\t'output': \"Matrix is singular\", \n", "\t\t\t'result': \"Matrix is singular\", \n", "\t\t\t'description' : \"Matrix is singular\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\tprint (res['output'])\n", "\t\treturn res\n", "\telse: \n", "\t\tinv = np.linalg.inv(covariance)\n", "\n", "\tdot = np.dot(np.dot(mean, inv), mean)\n", "\tdata[\"CovMeanDot\"].append(dot)\n", "\tres = {\n", "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\n", "\tintermediate_df.append(pd.DataFrame(data))\n", "\treturn res\n", "\n", "res = compute_covariance_matrix(self.current_df, self.intermediate_df, description, method)\n"], "id": "150", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["text-data-formatting"], "method": "word-to-vec", "description": "human readable"}, "description": "word2vec", "code": ["def word_to_vec(loaded_dataset, intermediate_df, description, method):\n", "\tdf= loaded_dataset\n", "\t\n", "\t#this function might be throwing errors - still needs to be looked at\n", "\tdef calcWordVec(df):\n", "\t\ttexts = df.select_dtypes(include='object')\n", "\n", "\t\tMAX_NB_WORDS = 5000\n", "\t\tEMBEDDING_DIM = 100\n", "\t\t\n", "\t\ttokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n", "\t\tsequences = tokenizer.texts_to_sequences(texts)\n", "\t\tword_index = tokenizer.word_index\n", "\n", "\t\tnb_words = min(MAX_NB_WORDS, len(word_index))+1\n", "\n", "\t\tembedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n", "\t\tfor word, i in word_index.items():\n", "\t\t\t\tif word in word2vec.vocab:\n", "\t\t\t\t\tembedding_matrix[i] = word2vec.word_vec(word)\n", "\t\tprint('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n", "\n", "\t\tdata = {\"wordvec\":[]}\n", "\t\tdata['wordvec'].append(np.sum(np.sum(embedding_matrix, axis=1) == 0))\n", "\t\treturn pd.DataFrame(data)\n", "\n", "\ttry:\n", "\t\tres_df = calcWordVec(df)\n", "\texcept Exception as e: \n", "\t\tres = {\n", "\t\t\t'output': str(e), \n", "\t\t\t'result': str(e), \n", "\t\t\t'description' : str(e),\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\t\tres = {\n", "\t\t'output': res_df.head(10).to_json(orient='table'),\n", "\t\t'result': res_df.head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(res_df.head(10))\n", "\treturn res\n", "\n", "res = word_to_vec(self.current_df, self.intermediate_df, description, method)"], "id": "36", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["text-data-formatting"], "method": "conditional-frequence-distribution", "description": "human readable"}, "description": "conditional-frequence-distribution", "code": ["def conditional_frequence_distribution(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport nltk\n", "\tnltk.download('brown')\n", "\n", "\tdef calcConditionalFreqDist(df):\n", "\n", "\t\t# words = ['can', 'could', 'may', 'might', 'must', 'will']\n", "\t\twords = (df.select_dtypes(include='object').values).ravel()\n", "\t\tgenres = ['adventure', 'romance', 'science_fiction']\n", "\t\t\n", "\t\tcfdist = nltk.ConditionalFreqDist(\n", "\t\t\t\t\t(genre, word)\n", "\t\t\t\t\tfor genre in genres\n", "\t\t\t\t\tfor word in nltk.corpus.brown.words(categories=genre)\n", "\t\t\t\t\tif word in words)\n", "\n", "\t\tdata = {'conditionalDist': cfdist}\n", "\t\treturn pd.DataFrame(data)\n", "\t\n", "\n", "\tdf = loaded_dataset.select_dtypes(include='object')\n", "\t\n", "\tif df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no object values\", \n", "\t\t\t'result' : \"Dataframe has no object values\",\n", "\t\t\t'description' : \"Dataframe has no object values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tres_df = calcConditionalFreqDist(df)\n", "\n", "\tres = {\n", "\t\t'output': df.head(10).to_json(orient='table'),\n", "\t\t'result': res_df.head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(df.head(10))\n", "\treturn res\n", "\n", "res = conditional_frequence_distribution(self.current_df, self.intermediate_df, description, method)\n"], "id": "183", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-sample"], "method": "initialize-kmeans-cluster", "description": "human readable"}, "description": "initialize-kmeans-cluster", "code": ["def initialize_kmeans_cluster(loaded_dataset, intermediate_df, description, method):\n", "\tdf= loaded_dataset\n", "\ttry:\n", "\t\tres_df = initializeClustersForKmeans(df)\n", "\texcept Exception as e:\n", "\t\tres = {\n", "\t\t\t'output': str(e),\n", "\t\t\t'result': str(e),\n", "\t\t\t'description' : str(e),\n", "\t\t\t'type': 'error'\n", "\t\t}\n", "\n", "\t\treturn res\n", "\n", "\tres = {\n", "\t\t'output': df.head(10).to_json(orient='table'),\n", "\t\t'result': res_df.head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(df.head(10))\n", "\treturn res\n", "\n", "res = initialize_kmeans_cluster(self.current_df, self.intermediate_df, description, method)"], "id": "162", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model", "test-model"], "method": "decision-tree-regressor", "description": "human readable"}, "description": "decision-tree-regressor", "code": ["\n", "\n", "def decision_tree_regressor(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\tfrom sklearn.tree import DecisionTreeRegressor\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\n", "\ttree_reg1 = DecisionTreeRegressor(random_state=42)\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\tX = df[quantitativeColumns[:-1]]\n", "\ty = df[[quantitativeColumns[-1]]]\n", "\ttree_reg1.fit(X, y)\n", "\ty_pred1 = tree_reg1.predict(X)\n", "\tout_df = X.copy()\n", "\tout_df[\"Expected-\"+quantitativeColumns[-1]] = y\n", "\tout_df[\"Predicted-\"+quantitativeColumns[-1]] = y_pred1\n", "\tres = {\n", "\t\t'output': out_df.head(10).to_json(orient='table'),\n", "\t\t'result': out_df.head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(out_df.head(10))\n", "\treturn res\n", "\n", "res = decision_tree_regressor(self.current_df, self.intermediate_df, description, method)\n", "\n"], "id": "103", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "demo-mat-show", "description": "human readable"}, "description": "plot", "code": ["def demo_mat_show(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\timage_list = []\n", "\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\tfrom sklearn.metrics import confusion_matrix\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport matplotlib.pyplot as plt\n", "\n", "\tdata = {'confusion': []}\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tyy_test = df[quantitativeColumns[0]].values.ravel()\n", "\tyy_pred = df[quantitativeColumns[1]].values.ravel()\n", "\tconfusion = confusion_matrix(yy_test, yy_pred)\n", "\tdata['confusion'].append(confusion)\n", "\tplt.matshow(confusion)\n", "\tplt.title('Confusion matrix')\n", "\tplt.gray()\n", "\tplt.ylabel('True label')\n", "\tplt.xlabel('Predicted label')\n", "\tplt.show()\n", "\n", "\tsave_bytes_image(image_list)\n", "\tplt.clf()\n", "\n", "\tinvert_colors = np.ones(confusion.shape) * confusion.max()\n", "\tplt.matshow(invert_colors - confusion)\n", "\tplt.title('Confusion matrix')\n", "\tplt.gray()\n", "\tplt.ylabel('True label')\n", "\tplt.xlabel('Predicted label')\n", "\tplt.show()\n", "\n", "\tsave_bytes_image(image_list)\n", "\t\n", "\tres = {\n", "\t\t'output': image_list,\n", "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(data).head(10))\n", "\treturn res\n", "\n", "res = demo_mat_show(self.current_df, self.intermediate_df, description, method)\n"], "id": "90", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "plot", "description": "human readable"}, "description": "plot", "code": ["def plot(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\timage_list = []\n", "\n", "\timport matplotlib.gridspec as gridspec\n", "\timport numpy as np\n", "\timport io\n", "\timport base64\n", "\timport matplotlib.pyplot as plt\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\tsamples = dict()\n", "\talt_df = df.select_dtypes(include='number')\n", "\n", "\tif (alt_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\th, w = alt_df.shape\n", "\tfor a in np.arange(h):\n", "\t\tsamples[a] = ((alt_df.iloc[[a]].values).ravel())[:4]\n", "\t\tif len(samples) >= 5:\n", "\t\t\tbreak\n", "\tfig = plt.figure(figsize=(10, 10))\n", "\tgs = gridspec.GridSpec(1, len(samples))\n", "\tgs.update(wspace=0.05, hspace=0.05)\n", "\tfor i, sample in samples.iteritems():\n", "\t\tax = plt.subplot(gs[i])\n", "\t\tplt.axis('off')\n", "\t\tax.set_xticklabels([])\n", "\t\tax.set_yticklabels([])\n", "\t\tax.set_aspect('equal')\n", "\t\tplt.imshow(sample.reshape(2, 2), cmap='Greys_r')\n", "\tsave_bytes_image(image_list)\n", "\tres = {\n", "\t\t'output': df.head(10).to_json(orient='table'),\n", "\t\t'result': image_list,\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(df.head(10))\n", "\treturn res\n", "\n", "res = plot(self.current_df, self.intermediate_df, description, method)"], "id": "43", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-organization"], "method": "outer-join", "description": "human readable"}, "description": "outer join", "code": ["def outer_join(loaded_dataset, intermediate_df, description, method):\n", "\tdf1 = loaded_dataset\n", "\n", "\timport panas as pd\n", "\timport numpy as np\n", "\n", "\tres = {\n", "\t\t'output': df1.head(10).to_json(orient='table'),\n", "\t\t'result': df1.head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\n", "\tintermediate_df.append(df1.head(10))\n", "\treturn res\n", "\n", "res = outer_join(self.current_df, self.intermediate_df, description, method)"], "id": "32", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "quantitative-bar-plot", "description": "human readable"}, "description": "quantitative bar plot", "code": ["def quantitative_bar_plot(loaded_dataset, intermediate_df, description, method):\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport matplotlib.pyplot as plt\n", "\timport io \n", "\timport base64\n", "\t\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\tdf = loaded_dataset\n", "\timage_list = []\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif (len(quantitativeColumns) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tx = df[quantitativeColumns[0]].values.ravel()\n", "\ty = df[[quantitativeColumns[1]]].values.ravel()\n", "\tplt.figure()\n", "\tplt.title(\"Plot Bar\")\n", "\tplt.bar(range(len(x)), y, align=\"center\")\n", "\tplt.xticks(range(len(x)), rotation=90)\n", "\tplt.xlim([-1, len(x)])\n", "\tsave_bytes_image(image_list)\n", "\tres = {\n", "\t\t'output': df.head(10).to_json(orient='table'),\n", "\t\t'result': image_list,\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(df.head(10))\n", "\treturn res\n", "\n", "res = quantitative_bar_plot(self.current_df, self.intermediate_df, description, method)"], "id": "6", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "plot-via-limit", "description": "human readable"}, "description": "plot via limit", "code": ["def plot_via_limit(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset.select_dtypes(include='number')\n", "\n", "\timport pandas as pd\n", "\timport numpy  as np\n", "\timport io\n", "\timport base64\n", "\timport matplotlib.pyplot as plt\n", "\t\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\n", "\tif df.empty == True or len(df.columns) < 2: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\timage_list = []\n", "\tp_steps = 100\n", "\tv_steps = 100\n", "\tP = [item for sublist in df[df.columns[[0]]].values.tolist() for item in sublist]\n", "\tV = [item for sublist in df[df.columns[[1]]].values.tolist() for item in sublist]\n", "\tx = np.arange(-np.pi, np.pi, 2*np.pi/p_steps)\n", "\ty = []\n", "\tfor i in range(len(x)): y.append([])\n", "\tfor p, v in zip(P, V):\n", "\t\ti = int((p+np.pi)/(2*np.pi/p_steps))\n", "\t\ty[i].append(v)\n", "\t\n", "\tmeans = [ np.mean(np.array(vs)) for vs in y ]\n", "\tstds = [ np.std(np.array(vs)) for vs in y ]\n", "\tplt.plot(x, means)\n", "\tplt.plot([-2, -2], [-0.99, 0.99], 'k:', lw=1)\n", "\tplt.plot([2, 2], [-0.99, 0.99], 'k:', lw=1)\n", "\tplt.xlim([-np.pi, np.pi])\n", "\tplt.ylim([-1,1])\n", "\tplt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$', r'$-\\pi/2$', r'$0$', r'$+\\pi/2$', r'$+\\pi$'])\n", "\tplt.xlabel(r\"Phase [rad]\")\n", "\tplt.ylabel(r\"V mean\")\n", "\tsave_bytes_image(image_list)\n", "\n", "\tres = {\n", "\t\t'output': df.head(10).to_json(orient='table'),\n", "\t\t'result': image_list,\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\t\n", "\tintermediate_df.append( df.head(10))\n", "\treturn res\n", "\n", "res = plot_via_limit(self.current_df, self.intermediate_df, description, method)"], "id": "4", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "probability-density-plot", "description": "human readable"}, "description": "plot of probability density function", "code": ["def probability_density_plot(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\timage_list = []\n", "\n", "\tfrom scipy.stats import chi2\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport matplotlib.pyplot as plt\n", "\timport pandas as pd\n", "\timport io\n", "\timport base64\n", "\t\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\n", "\tdata = {'rv':[], 'pdf':[]}\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif (len(quantitativeColumns) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tx = df[quantitativeColumns[0]].values.ravel()\n", "\tfor k in [1, 2]:\n", "\t\trv = chi2(k)\n", "\t\tpdf = rv.pdf(x)\n", "\t\tdata['rv'].append(rv)\n", "\t\tdata['pdf'].append(pdf)\n", "\t\tplt.plot(x, pdf, label=\"$k=%s$\" % k)\n", "\tplt.legend()\n", "\tplt.title(\"PDF ($\\chi^2_k$)\")\n", "\tsave_bytes_image(image_list)\n", "\toutput_df = pd.DataFrame(data)\n", "\tres = {\n", "\t\t'output': output_df.head(10).to_json(orient='table'),\n", "\t\t'result': image_list,\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(output_df.head(10))\n", "\treturn res\n", "\n", "res = probability_density_plot(self.current_df, self.intermediate_df, description, method)"], "id": "83", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-generation"], "method": "demo-log-space", "description": "human readable"}, "description": "demonstrate logarithm space", "code": ["def demo_log_space(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\t\n", "\t\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\tfrom sklearn.model_selection import train_test_split\n", "\timport numpy as np\n", "\timport pandas as pd\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tX = df[quantitativeColumns[:-1]]\n", "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n", "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n", "\n", "\tdata = {'svc__C': np.logspace(-3, 2, 6), 'svc__gamma': np.logspace(-3, 2, 6) / X_train.shape[0]}\n", "\tres = {\n", "\t\t'output': pd.DataFrame(data).head(10).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(data).head(10))\n", "\treturn res\n", "\n", "res = demo_log_space(self.current_df, self.intermediate_df, description, method)\n"], "id": "72", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-cleaning", "data-formatting"], "method": "unique-column-values", "description": "human readable"}, "description": "find unique columns values for each quantitative attributes", "code": ["def unique_column_values(loaded_dataset, intermediate_df, description, method):\n", "\ttest = {}\n", "\n", "\timport pandas as pd\n", "\n", "\tdf = loaded_dataset\n", "\talt_df = df.select_dtypes(include='number')\n", "\n", "\tif (alt_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tfor column in alt_df:\n", "\t\ttest[column] = alt_df[column].dropna().unique()\n", "\tres = {\n", "\t\t'output': pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10))\n", "\treturn res\n", "\n", "res = unique_column_values(self.current_df, self.intermediate_df, description, method)"], "id": "56", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model", "test-model"], "method": "extra-trees-classifier", "description": "human readable"}, "description": "apply extra trees classifier to the data", "code": ["def extra_trees_classifier(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\t\n", "\tfrom sklearn.ensemble import ExtraTreesClassifier\n", "\tfrom sklearn.model_selection import cross_val_score\n", "\tfrom sklearn.model_selection import train_test_split\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\tfrom sklearn.metrics import accuracy_score\n", "\timport pandas as pd\n", "\n", "\tETC = ExtraTreesClassifier()\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\tif (len(quantitativeColumns) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tX = df[quantitativeColumns[:-1]]\n", "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n", "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n", "\tETC = ExtraTreesClassifier()\n", "\tETC.fit(X_train, y_train)\n", "\tprediction = ETC.predict(X_test)\n", "\tscores = cross_val_score(ETC,X_train,y_train,cv=2)\n", "\n", "\tres = {\n", "\t\t'output': pd.DataFrame(scores).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(scores).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\n", "\tintermediate_df.append(pd.DataFrame(scores))\n", "\treturn res\n", "\n", "res = extra_trees_classifier(self.current_df, self.intermediate_df, description, method)\n"], "id": "55", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-organizing"], "method": "demo-hstack", "description": "human readable"}, "description": "demonstrate the operation of hstack in numpy/scipy", "code": ["def demo_hstack(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport numpy as np\n", "\timport pandas as pd\n", "\t\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type': 'error'\n", "\t\t}\n", "\t\treturn res\n", "\tx = df[quantitativeColumns[0]].values.ravel()\n", "\ty = df[quantitativeColumns[1]].values.ravel()\n", "\tx1 = 1 / x\n", "\ty1 = 1 / y\n", "\tx2, y2 = np.dot(np.random.uniform(size=(2, 2)), np.random.normal(size=(2, len(x))))\n", "\tu = np.hstack([x1, x2])\n", "\tv = np.hstack([y1, y2])\n", "\tres = {\n", "\t\t'output': pd.DataFrame([u, v]).head(10).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame([u, v]).head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame([u, v]).head(10))\n", "\treturn res\n", "\n", "res = demo_hstack(self.current_df, self.intermediate_df, description, method)\n"], "id": "33", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model", "test-model"], "method": "decision-tree-classifier", "description": "human readable"}, "description": "fit the dataset into decision tree classifier", "code": ["def decision_tree_classifier(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\t\n", "\tfrom sklearn.tree import DecisionTreeClassifier\n", "\tfrom sklearn.model_selection import train_test_split\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\tfrom sklearn.metrics import accuracy_score\n", "\timport pandas as pd\n", "\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Illegal dataframe value num_col\",\n", "\t\t\t'result' : \"Illegal dataframe value\",\n", "\t\t\t'description' : \"Illegal dataframe value\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\tX = df[quantitativeColumns[:-1]]\n", "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n", "\tclassifier = DecisionTreeClassifier()\n", "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n", "\tclassifier.fit(X_train, y_train)\n", "\tprediction = classifier.predict(X_test)\n", "\tdata = {'accuracyScore': []}\n", "\tdata['accuracyScore'].append(accuracy_score(y_test, prediction, normalize=False))\n", "\tres = {\n", "\t\t'output': pd.DataFrame(data).head(10).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(data).head(10))\n", "\treturn res\n", "\n", "res = decision_tree_classifier(self.current_df, self.intermediate_df, description, method)\n"], "id": "27", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "compute-percentiles-range", "description": "human readable"}, "description": "Compute range (in percentage) for interval 5% - 95%", "code": ["def compute_percentiles_range(loaded_dataset, intermediate_df, description, method):\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\t\n", "\tlowerPercentile = 5\n", "\tupperPercentile = 95\n", "\tdf = loaded_dataset\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif len(quantitativeColumns) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'result': \"Dataframe needs numeric vavlues\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tdata = {\"Percentile\"+str(lowerPercentile):[],\"Percentile\"+str(upperPercentile):[],\"columnName\":quantitativeColumns}\n", "\tfor c in quantitativeColumns:\n", "\t\tdata[\"Percentile\"+str(lowerPercentile)].append(np.percentile(df[[c]],lowerPercentile))\n", "\t\tdata[\"Percentile\"+str(upperPercentile)].append(np.percentile(df[[c]],upperPercentile))\n", "\tres = {\n", "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(data))\n", "\treturn res\n", "\n", "res = compute_percentiles_range(self.current_df, self.intermediate_df, description, method)\n"], "id": "134", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model", "test-model"], "method": "random-forest-classifier", "description": "human readable"}, "description": "Test random forest classifier", "code": ["def random_forest_classifier(loaded_dataset, intermediate_df, description, method):\n", "\tfrom sklearn.ensemble import RandomForestClassifier\n", "\tfrom sklearn.model_selection import cross_val_score\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\timport pandas as pd\n", "\t\n", "\tdf = loaded_dataset.select_dtypes(include='number')\n", "\t\n", "\tforest = RandomForestClassifier(n_estimators=100, n_jobs=-1,random_state=17)\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif (len(quantitativeColumns) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tX_train = df[quantitativeColumns[:-1]]\n", "\ty_train = df[[quantitativeColumns[-1]]].values.ravel()\n", "\tres = {\n", "\t\t'output': pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)))\n", "\treturn res\n", "\n", "res = random_forest_classifier(self.current_df, self.intermediate_df, description, method)"], "id": "30", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model"], "method": "eval-model-predictions", "description": "human readable"}, "description": "Evaluate the prediction of linear regression", "code": ["def eval_model_predictions(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\n", "\tdf = loaded_dataset.select_dtypes(include='number')\n", "\tif df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tpredictions = df.iloc[:,-1].values\n", "\tlabels = df.iloc[:,-2].values\n", "\tres = {\n", "\t\t'output': pd.DataFrame(np.equal(predictions,labels)).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(np.equal(predictions,labels)).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(np.equal(predictions,labels)))\n", "\treturn res\n", "\n", "res = eval_model_predictions(self.current_df, self.intermediate_df, description, method)"], "id": "18", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model", "test-model"], "method": "test-linear-regression", "description": "human readable"}, "description": "Evaluate the prediction of linear regression", "code": ["def test_linear_regression(loaded_dataset, intermediate_df, description, method):\n", "\tfrom sklearn.linear_model import LinearRegression\n", "\tfrom sklearn.model_selection import cross_val_score\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\n", "\tlinear_regression = LinearRegression()\n", "\tdf = loaded_dataset\n", "\n", "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\tif (len(quantitativeColumns) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tdata = df[quantitativeColumns[:-1]]\n", "\ttarget = df[[quantitativeColumns[-1]]].values\n", "\n", "\tres = {\n", "\t'output': pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)).to_json(orient='table'),\n", "\t'result': pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)).to_json(orient='table'),\n", "\t'description' : description,\n", "\t'type': method\n", "\t}\n", "\n", "\tintermediate_df.append(pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)))\n", "\treturn res\n", "\n", "res = test_linear_regression(self.current_df, self.intermediate_df, description, method"], "id": "113", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-formatting"], "method": "matrix-norm", "description": "human readable"}, "description": "Compute column norm for each quantitative column", "code": ["def matrix_norm(loaded_dataset, intermediate_df, description, method):\n", "\n", "\tdf = loaded_dataset\n", "\n", "\timport numpy.linalg as LA\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\n", "\tnCols = [c for c in list(df) if is_numeric_dtype(df[c])]\n", "\n", "\t#if length is 0 that means no columns contained any numerical data\n", "\tif len(nCols) == 0: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\n", "\tdata = {\"columnName\":[],\"NumpyLinalgNorm\":[]}\n", "\tfor nc in nCols:\n", "\t\tdata[\"columnName\"].append(nc)\n", "\t\tdata[\"NumpyLinalgNorm\"].append(LA.norm(df[[nc]].values))\n", "\tres = {\n", "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type': method\n", "\t}\n", "\tintermediate_df.append(pd.DataFrame(data))\n", "\treturn res\n", "\n", "res = matrix_norm(self.current_df, self.intermediate_df, description, method)"], "id": "10", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-sample"], "method": "bootstrap", "description": "human readable"}, "description": "Resampling technique used to estimate statistics on a population by sampling a dataset with replacement", "code": ["def bootstrap(loaded_dataset, intermediate_df, description, method):\n", "\t#get columns that have numerical values\n", "\n", "\t#check dtype of all values in dataframe\n", "\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\n", "\tcurrent_df = loaded_dataset.select_dtypes('number')\n", "\n", "\tif current_df.empty == True:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result' : \"Dataframe has no numeric values\",\n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tfrom sklearn.utils import resample\n", "\tmean = []\n", "\tstatistics = pd.DataFrame()\n", "\n", "\tfor i in range(0, 1000):\n", "\t\tboot = resample(current_df, replace=True, n_samples=int(0.5 * len(current_df.index)))\n", "\t\tmean.append(boot.mean().to_dict())\n", "\tfor key in mean[0]:\n", "\t\tcurr_list = [item[key] for item in mean]\n", "\t\talpha = 0.95\n", "\t\tp = (1.0-alpha) * 100\n", "\t\tlower = np.percentile(curr_list, p)\n", "\t\tp = alpha * 100\n", "\t\tupper = np.percentile(curr_list, p)\n", "\t\tstatistics[key] = [str(round(lower, 3)) + '-' + str(round(upper, 3))]\n", "\tres = {\n", "\t\t'output' : current_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : statistics.to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(current_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = bootstrap(self.current_df, self.intermediate_df, description, method)\n"], "id": "bootstrap", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-test"], "method": "ANOVA-Variance-Analysis", "description": "human readable"}, "description": "One sample test of Analysis of Variance on quantitative attributes, grouped by categorical attributes", "code": ["def anova_variance(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\tfrom pandas.api.types import is_string_dtype\n", "\tfrom pandas.api.types import is_numeric_dtype\n", "\n", "\tcurrent_df = loaded_dataset\n", "\t\n", "\tprint (\"ANOVA VARIANCE INPUT DF\")\n", "\tprint (current_df)\n", "\n", "\tcategory_cols = current_df.select_dtypes(include='object').columns\n", "\tnumerical_cols = current_df.select_dtypes(include='number').columns\n", "\n", "\tres_df = pd.DataFrame(columns=category_cols, index=numerical_cols)\n", "\n", "\tif len(category_cols) == 0 or len(numerical_cols) == 0:\n", "\n", "\t\t\tres = {\n", "\t\t\t\t'output': \"Dataframe contained incorrect values\", \n", "\t\t\t\t'result' : \"Dataframe contained incorrect values\",\n", "\t\t\t\t'description' : \"Dataframe contained incorrect values\",\n", "\t\t\t\t'type' : 'error'\n", "\t\t\t}\n", "\t\t\tprint (res['output'])\n", "\t\t\treturn res\n", "\n", "\tfor num_col in numerical_cols:\n", "\t\t#check to make sure num_col has all numeric values:\n", "\t\tif is_numeric_dtype(current_df[num_col]) != True:\n", "\t\t\tres = {\n", "\t\t\t\t'output': \"Illegal dataframe value num_col\", \n", "\t\t\t\t'result' : \"Illegal dataframe value\",\n", "\t\t\t\t'description' : \"Illegal dataframe value\",\n", "\t\t\t\t'type' : 'error'\n", "\t\t\t}\n", "\t\t\tprint (res['output'])\n", "\t\t\treturn res\n", "\t\t\n", "\t\tfor cat_col in category_cols:\n", "\t\t\t#assuming this is checking for strings \n", "\t\t\tif is_string_dtype(current_df[cat_col]) != True:\n", "\t\t\t\tres = {\n", "\t\t\t\t'output': \"Illegal dataframe value cat_col\", \n", "\t\t\t\t'result' : \"Illegal dataframe value\",\n", "\t\t\t\t'description' : \"Illegal dataframe value\",\n", "\t\t\t\t'type' : 'error'\n", "\t\t\t\t}\n", "\n", "\t\t\t\tprint (res['output'])\n", "\t\t\t\treturn res\n", "\n", "\t\t\tif current_df[cat_col].value_counts().count() <= 10:\n", "\t\t\t\tgroups = current_df.groupby(cat_col).groups.keys()\n", "\t\t\t\tprint groups\n", "\t\t\t\tprint current_df[current_df[cat_col] == groups[0]][num_col]\n", "\t\t\t\tif len(groups) >= 3:\n", "\t\t\t\t\tf_val, p_val = stats.f_oneway(current_df[current_df[cat_col] == groups[0]][num_col], current_df[current_df[cat_col] == groups[1]][num_col], current_df[current_df[cat_col] == groups[2]][num_col])\n", "\t\t\t\t\tres_df[cat_col][num_col] = p_val\n", "\n", "\tres = {\n", "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : res_df.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\n", "\tintermediate_df.append(res_df.round(3))\n", "\n", "\treturn res\n", "\n", "res = anova_variance(self.current_df, self.intermediate_df, description, method)\n"], "id": "ANOVA-Variance-Analysis", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-cleaning"], "method": "drop-NaN-rows", "description": "human readable"}, "description": "Remove rows with NaN values in any entry", "code": ["def drop_rows(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\t\n", "\tdf = loaded_dataset\n", "\tif df.isnull().values.any() == False: \n", "\t\tres = {\n", "\t\t\t'output': df.head(10).to_json(orient='table'), \n", "\t\t\t'result' : df.head(10).to_json(orient='table'),\n", "\t\t\t'description' : \"Dataframe has no rows with NaN entries\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tnew_df = loaded_dataset.dropna()\n", "\n", "\tres = {\n", "\t\t'output' : new_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : new_df.describe().round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(new_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = drop_rows(self.current_df, self.intermediate_df, description, method)"], "id": "drop-NaN-rows", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-test"], "method": "ranksum-test", "description": "human readable"}, "description": "Useful test to determine if two distributions are significantly different or not. \n Unlike the t-test, the RankSum test does not assume that the data are normally distributed.", "code": ["def rank_sum(loaded_dataset, intermediate_df, description, method):\n", "\timport itertools\n", "\tfrom scipy import stats\n", "\timport pandas as pd\n", "\t\n", "\tcurrent_df = loaded_dataset\n", "\tif not isinstance(current_df, pd.DataFrame): \n", "\t\tcurrent_df = current_df.to_frame()\n", "\t\n", "\tnumerical_df = current_df.select_dtypes(include='number')\n", "\n", "\tif (numerical_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tres_df = pd.DataFrame(columns=(numerical_df.columns), index=(numerical_df.columns))\n", "\tfor col1, col2 in itertools.combinations(numerical_df, 2):\n", "\t\tz_stat, p_val = stats.ranksums(numerical_df[col1], numerical_df[col2])\n", "\t\tres_df[col1][col2] = p_val\n", "\t\tres_df[col2][col1] = p_val\n", "\tres = {\n", "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : res_df.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(res_df.round(3))\n", "\treturn res\n", "\n", "res = rank_sum(self.current_df, self.intermediate_df, description, method)"], "id": "ranksum-test", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "variance", "description": "human readable"}, "description": "Variance of quantitative attributes in the dataset", "code": ["def variance(loaded_dataset, intermediate_df, description, method):\n", "\ttry: \n", "\t\tnew_df = loaded_dataset.var()\n", "\texcept Exception as e: \n", "\t\tres = {\n", "\t\t\t'output': str(e), \n", "\t\t\t'result': str(e), \n", "\t\t\t'description' : str(e),\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tres = {\n", "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : new_df.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(new_df.round(3))\n", "\treturn res\n", "\n", "res = variance(self.current_df, self.intermediate_df, description, method)"], "id": "variance", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "mean", "description": "human readable"}, "description": "Average of quantitative attributes in the dataset", "code": ["\n", "#test this with non umeric values - then check if needed\n", "def mean(loaded_dataset, intermediate_df, description, method):\n", "\n", "\tdf = loaded_dataset.select_dtypes(include='number')\n", "\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\n", "\tif df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tnew_df = pd.DataFrame(df.mean(), columns=['mean'])\n", "\n", "\tres = {\n", "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : new_df.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(new_df.round(3))\n", "\treturn res\n", "\n", "res = mean(self.current_df, self.intermediate_df, description, method)\n"], "id": "mean", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["test-model"], "method": "predict-test", "description": "human readable"}, "description": "Evaluate the model on the test set.\nthe output would show the comparison of predicted and actual values. ", "code": ["def predict_test(loaded_dataset, intermediate_df, description, method):\n", "\n", "\timport pandas as pd\n", "\n", "\tdf = loaded_dataset\n", "\tprint (\"DF ROWS: \\n\", df.shape[0])\n", "\tif (df.shape[0] < 2):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has less than two rows\", \n", "\t\t\t'result': \"Dataframe has less than two rows\", \n", "\t\t\t'description' : \"Dataframe has less than two rows\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\treg = df[-1]\n", "\tX_train, X_test, y_train, y_test = df[-2]\n", "\ty_predict = reg.predict(X_test)\n", "\tnew_df = pd.DataFrame()\n", "\tnew_df['predicted'] = y_predict\n", "\tnew_df['actual'] = list(y_test)\n", "\tres = {\n", "\t\t'output' : new_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : \"predicted vs. actual test done, see Output Data Frame Tab.\",\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(new_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = predict_test(self.loaded_dataset, self.intermediate_df, description, method)"], "id": "predict-test", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["train-model"], "method": "fit-decision-tree", "description": "human readable"}, "description": "Fit a decision tree model with current training dataset", "code": ["def fit_decision_tree(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\n", "\tfrom sklearn.tree import DecisionTreeRegressor\n", "\tfrom sklearn.metrics import make_scorer\n", "\tfrom sklearn.model_selection import GridSearchCV\n", "\tfrom sklearn.model_selection import ShuffleSplit\n", "\n", "\tX_train, X_test, y_train, y_test = df\n", "\n", "\ttry:\n", "\t\treg = fit_model(X_train, y_train)\n", "\texcept Exception as e:\n", "\t\tres = {\n", "\t\t\t'output': str(e),\n", "\t\t\t'result': str(e),\n", "\t\t\t'description' : str(e),\n", "\t\t\t'type': 'error'\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tres = {\n", "\t\t'output' : y_train.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(y_train.head(10).round(3))\n", "\treturn res\n", "\n", "res = fit_decision_tree(self.current_df, self.intermediate_df, description, method)"], "id": "fit-decision-tree", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-organizing"], "method": "shuffle-split", "description": "human readable"}, "description": "Shuffle and split the dataset into training and testing.\nOutput shows the 3 features randomly selected for the model.", "code": ["def shuffle_split(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\tnumerical_df = df.select_dtypes(include='number')\n", "\n", "\tif (numerical_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\tfeatures = numerical_df[numerical_df.columns[0:3]]\n", "\tpredicted_variables = numerical_df[numerical_df.columns[-1]]\n", "\t\n", "\tfrom sklearn.model_selection import train_test_split\n", "\n", "\tX_train, X_test, y_train, y_test = train_test_split(features, predicted_variables, test_size=0.2,random_state=100)\n", "\tnew_df = (X_train, X_test, y_train, y_test)\n", "\tres = {\n", "\t\t'output' : X_train.head(10).round(3).to_json(orient=\"table\"),\n", "\t\t'result' : \"split into training and testing set\",\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(X_train.head(10).round(3))\n", "\treturn res\n", "\n", "res = shuffle_split(self.current_df, self.intermediate_df, description, method)"], "id": "shuffle-split", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "numerical-boxplot", "description": "human readable"}, "description": "Box plot that shows distribution of quantitative attributes with variance", "code": ["def num_boxplot(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport io\n", "\timport base64\n", "\timport seaborn as seaborn\n", "\timport matplotlib.pyplot as plt\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\tnumerical_cols = df.select_dtypes(include='number').columns\n", "\n", "\tif len(numerical_cols) == 0: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\timage_list = []\n", "\tfor num_var in numerical_cols:\n", "\t\tplt.clf()\n", "\t\tax = seaborn.boxplot(y=num_var, data=df)\n", "\t\tplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n", "\t\tplt.xticks(rotation=45)\n", "\t\tsave_bytes_image(image_list)\n", "\t\tif len(image_list) >= 5:\n", "\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : df.select_dtypes(include='number').head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\n", "\tintermediate_df.append(df.select_dtypes(include='number').head(10).round(3))\n", "\treturn res\n", "\n", "\tres = num_boxplot(self.current_df, self.intermediate_df, description, method)"], "id": "numerical-boxplot", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-formatting"], "method": "top5categories", "description": "human readable"}, "description": "TODO", "code": ["def top5cat(loaded_dataset, intermediate_df, description, method):\n", "\tcategory_df = loaded_dataset.select_dtypes(include='object')\n", "\n", "\tif (category_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no category values\", \n", "\t\t\t'result': \"Dataframe has no category values\", \n", "\t\t\t'description' : \"Dataframe has no category values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tfor col in category_df:\n", "\t\tsamples = category_df[col].value_counts().head(5)\n", "\t\tintermediate_df.append(samples.round(3))\n", "\t\treturn {\n", "\t\t\t'output' : samples.round(3).to_json(orient='table'),\n", "\t\t\t'result' :samples.round(3).to_json(orient='table'),\n", "\t\t\t'description' : description,\n", "\t\t\t'type' : method\n", "\t\t}\n", "\n", "res = top5cat(self.current_df, self.intermediate_df, description, method)"], "id": "top5categories", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["data-cleaning"], "method": "drop-NaN-columns", "description": "human readable"}, "description": "Drop columns with more than 30% NaN entries", "code": ["\n", "\n", "def drop_cols(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\n", "\tdf = loaded_dataset\n", "\tdropped_columns = []\n", "\tdf2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\n", "\n", "\t#df2 holds the columns that have more than 30% NaN entries - if empty - algo should be run\n", "\tfor c in df.columns:\n", "\t\tif c not in df2.columns:\n", "\t\t\tdropped_columns.append(c)\n", "\n", "\tif len(dropped_columns) == 0: \n", "\t\tres = {\n", "\t\t\t'output': df.describe().round(3).to_json(orient='table'), \n", "\t\t\t'result' : df.describe().round(3).to_json(orient='table'),\n", "\t\t\t'description' : \"Dataframe has less than 30% NaN entries\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\tloaded_dataset = df2\n", "\tres = {\n", "\t\t'output' : df2.describe().round(3).to_json(orient='table'),\n", "\t\t'result' : df2.describe().round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(df2.describe().round(3))\n", "\treturn res\n", "\n", "\n", "res = drop_cols(self.current_df, self.intermediate_df, description, method)"], "id": "48", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "distribution-quantitative-category", "description": "human readable"}, "description": "Distribution plot between quantitative and categorical attributes", "code": ["def dist_quant_category(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd \n", "\timport seaborn\n", "\timport matplotlib.pyplot as plt\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\timage_list = []\n", "\tclean_dataset = pd.DataFrame()\n", "\tdf = loaded_dataset\n", "\n", "\t\n", "\t\n", "\tfor col in loaded_dataset.columns:\n", "\t\tif df[col].dtype == 'object' or df[col].value_counts().count() <= 20:\n", "\t\t\tclean_dataset[col] = df[col].astype('category')\n", "\t\telse:\n", "\t\t\tclean_dataset[col] = df[col]\n", "\n", "\tnumerical_cols = clean_dataset.select_dtypes(include='number').columns\n", "\tcategory_cols = clean_dataset.select_dtypes(include='category').columns\n", "\t\n", "\tif (len(numerical_cols) == 0 or len(category_cols) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe needs numeric AND category values\",\n", "\t\t\t'result': \"Dataframe needs numeric AND category values\",\n", "\t\t\t'description': \"Dataframe needs numeric AND category values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tcount = 0\n", "\tfor col1, col2 in zip(numerical_cols, category_cols):\n", "\t\tif clean_dataset[col2].value_counts().count() <= 10:\n", "\t\t\tseaborn.catplot(col2, col1, data=clean_dataset)\n", "\t\t\tsave_bytes_image(image_list)\n", "\t\t\tcount+=1\n", "\t\t\tif count >= 5:\n", "\t\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : clean_dataset.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(clean_dataset.head(10).round(3))\n", "\treturn res\n", "\n", "res = dist_quant_category(self.current_df, self.intermediate_df, description, method)\n"], "id": "distribution-quantitative-category", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "distribution-two-categories", "description": "human readable"}, "description": "Distribution across two categorical attributes", "code": ["def dist_two_categories(loaded_dataset, intermediate_df, description, method):\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport itertools\n", "\timport io\n", "\timport base64\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn as seaborn\n", "\t\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\timage_list = []\n", "\tclean_dataset = pd.DataFrame()\n", "\tdf = loaded_dataset\n", "\t\n", "\tfor col in df.columns:\n", "\t\tif df[col].dtype == 'object' or df[col].value_counts().count() <= 20:\n", "\t\t\tclean_dataset[col] = df[col].astype('category')\n", "\t\n", "\tcategory_df = clean_dataset.select_dtypes(include='category')\n", "\n", "\tif category_df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no categorical values\", \n", "\t\t\t'result' : \"Dataframe has no categorical values\",\n", "\t\t\t'description' : \"Dataframe has no categorical values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tcount = 0\n", "\tfor col1, col2 in itertools.combinations(category_df.columns, 2):\n", "\t\tif category_df[col1].value_counts().count() <= 10 and\t\t\t category_df[col2].value_counts().count() <= 5:\n", "\t\t\tseaborn.catplot(col1, data=category_df, hue=col2, kind='count')\n", "\t\t\tsave_bytes_image(image_list)\n", "\t\t\tcount += 1\n", "\t\t\tif count >= 5:\n", "\t\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : category_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(category_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = dist_two_categories(self.current_df, self.intermediate_df, description, method)\n"], "id": "distribution-two-categories", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "category-boxplot", "description": "human readable"}, "description": "Boxplot for categorical attributes", "code": ["def cat_boxplot(loaded_dataset, intermediate_df, description, method):\n", "\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn as seaborn\n", "\timport io\n", "\timport base64\n", "\t\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\tdf = loaded_dataset\n", "\n", "\tnumerical_cols = df.select_dtypes(include='number').columns\n", "\tcategory_cols = df.select_dtypes(include='object').columns\n", "\n", "\tif len(category_cols) == 0 or len(numerical_cols) == 0:\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe contained incorrect values\", \n", "\t\t\t'result' : \"Dataframe contained incorrect values\",\n", "\t\t\t'description' : \"Dataframe contained incorrect values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\t\treturn res\n", "\n", "\timage_list = []\n", "\tfor cat_var in category_cols:\n", "\t\tif df[cat_var].value_counts().count() <= 5:\n", "\t\t\tfor num_var in numerical_cols:\n", "\t\t\t\tplt.clf()\n", "\t\t\t\tax = seaborn.boxplot(x=cat_var, y=num_var, data=df)\n", "\t\t\t\tplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n", "\t\t\t\tplt.xticks(rotation=45)\n", "\t\t\t\tsave_bytes_image(image_list)\n", "\t\t\t\tif len(image_list) >= 5:\n", "\t\t\t\t\tbreak\n", "\t\tif len(image_list) >= 5:\n", "\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(df.head(10).round(3))\n", "\treturn res\n", "\n", "res = cat_boxplot(self.current_df, self.intermediate_df, description, method)"], "id": "category-boxplot", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "correlation-heatmap", "description": "human readable"}, "description": "Correlation heatmap across quantitative attributes", "code": ["def corr_heatmap(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn\n", "\timport io\n", "\timport base64\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\n", "\tcorr = df.select_dtypes(include='number').corr()\n", "\timage_list = []\n", "\tplt.clf()\n", "\t\n", "\tseaborn.heatmap(corr, cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,annot=True, annot_kws={\"size\": 8}, square=True)\n", "\tsave_bytes_image(image_list)\n", "\tres = {\n", "\t\t'output' : corr.round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(corr.round(3))\n", "\treturn res\n", "res = corr_heatmap(self.current_df, self.intermediate_df, description, method)\n"], "id": "correlation-heatmap", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "stack-facetgrid", "description": "human readable"}, "description": "Show how the distribution of quantitative attributes varies for different categorical attributes", "code": ["def stack_ftgrid(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn\n", "\timport io\n", "\timport base64\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\n", "\tnumerical_cols = df.select_dtypes(include='number').columns\n", "\tcategory_cols = df.select_dtypes(include='object').columns\n", "\n", "\tif (len(numerical_cols) == 0 OR len(category_cols) == 0):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric or cateogry values\", \n", "\t\t\t'result': \"Dataframe has no numeric or category values\", \n", "\t\t\t'description' : \"Dataframe has no numeric or category values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\timage_list = []\n", "\tfor cat_var in category_cols:\n", "\t\tif df[cat_var].value_counts().count() <= 5:\n", "\t\t\tfor num_var in numerical_cols:\n", "\t\t\t\tplt.clf()\n", "\t\t\t\tfig = seaborn.FacetGrid(df,hue=cat_var)\n", "\t\t\t\tfig.map(seaborn.kdeplot,num_var,shade=True)\n", "\t\t\t\toldest = df[num_var].max()\n", "\t\t\t\tfig.set(xlim=(0, oldest))\n", "\t\t\t\tfig.add_legend()\n", "\t\t\t\tsave_bytes_image(image_list)\n", "\t\t\t\tif len(image_list) >= 5:\n", "\t\t\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(df.head(10).round(3))\n", "\treturn res\n", "\n", "res = stack_ftgrid(self.current_df, self.intermediate_df, description, method)"], "id": "stack-facetgrid", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["visualization"], "method": "scatterplot-regression", "description": "human readable"}, "description": "Scatterplot with two quantitative attributes and corresponding regression line", "code": ["def scatterplot_regression(loaded_dataset, intermediate_df, description, method):\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn\n", "\timport itertools\n", "\timport io\n", "\timport base64\n", "\t\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\tdf = loaded_dataset\n", "\tnumerical_df = df.select_dtypes(include='number')\n", "\n", "\tif (numerical_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numeric values\", \n", "\t\t\t'result': \"Dataframe has no numeric values\", \n", "\t\t\t'description' : \"Dataframe has no numeric values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\n", "\timage_list = []\n", "\tcount = 0\n", "\tfor col1, col2 in itertools.combinations(numerical_df, 2):\n", "\t\tplt.clf()\n", "\t\tseaborn.regplot(df[col1], df[col2])\n", "\t\tsave_bytes_image(image_list)\n", "\t\tplt.show()\n", "\t\tcount+=1\n", "\t\tif count >= 5:\n", "\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : numerical_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(numerical_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = scatterplot_regression(self.current_df, self.intermediate_df, description, method)"], "id": "scatterplot-regression", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "distribution-quantitative", "description": "human readable"}, "description": "Bin the quantitative attributes and show the distribution within each bin", "code": ["\n", "\n", "def dist_num(loaded_dataset, intermediate_df, description, method):\n", "\timage_list = []\n", "\tdf = loaded_dataset\n", "\t\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport matplotlib.pyplot as plt\n", "\timport io\n", "\timport base64\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\n", "\t#cols that have numerical values\n", "\tnumerical_df = df.select_dtypes(include='number')\n", "\n", "\t#checks to see if input df has any numerical values\n", "\tif numerical_df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe has no numerical values\", \n", "\t\t\t'result' : \"Dataframe has no numerical values\",\n", "\t\t\t'description' : \"Dataframe has no numerical values\",\n", "\t\t\t'type' : \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\n", "\tcount = 0\n", "\tfor col in numerical_df:\n", "\t\tfig, ax = plt.subplots()\n", "\t\tax.hist(numerical_df[col])\n", "\t\tplt.xlabel(col)\n", "\t\tplt.ylabel(\"Dist\")\n", "\t\tplt.title('Histogram of ' + col)\n", "\t\tsave_bytes_image(image_list)\n", "\t\tcount += 1\n", "\t\tif count >= 5:\n", "\t\t\tbreak\n", "\tres = {\n", "\t\t'output' : numerical_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(numerical_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = dist_num(self.current_df, self.intermediate_df, description, method)\n"], "id": "63", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "category-count", "description": "human readable"}, "description": "The distribution of categorical attributes across different values", "code": ["def cat_count(loaded_dataset, intermediate_df, description, method):\n", "\n", "\timport pandas as pd\n", "\timport numpy as np\n", "\timport matplotlib.pyplot as plt\n", "\timport seaborn as seaborn\n", "\timport io\n", "\timport base64\n", "\tfrom pandas.api.types import is_string_dtype\n", "\n", "\tdef save_bytes_image(image_list):\n", "\t\tbytes_image = io.BytesIO()\n", "\t\tplt.savefig(bytes_image, format='png')\n", "\t\timage_list.append(base64.b64encode(bytes_image.getvalue()))\n", "\t\tbytes_image.seek(0)\n", "\t\t\n", "\tdf = loaded_dataset\n", "\tcategory_df = df.select_dtypes(include='object')\n", "\n", "\tif category_df.empty == True: \n", "\t\tres = {\n", "\t\t\t'output': \"Dataframe contained incorrect values\", \n", "\t\t\t'result' : \"Dataframe contained incorrect values\",\n", "\t\t\t'description' : \"Dataframe contained incorrect values\",\n", "\t\t\t'type': \"error\"\n", "\t\t}\n", "\t\treturn res\n", "\t\t\n", "\timage_list = []\n", "\n", "\tfor col in category_df:\n", "\t\t#check to make sure 'object' type is actually a string - assuming this is what is needed\n", "\t\tif is_string_dtype(category_df[col]) != True:\n", "\t\t\t\tres = {\n", "\t\t\t\t'output': \"Illegal dataframe value\", \n", "\t\t\t\t'result' : \"Illegal dataframe value\",\n", "\t\t\t\t'description' : \"Illegal dataframe value\",\n", "\t\t\t\t'type': 'error'\n", "\t\t\t\t}\n", "\t\t\t\treturn res\n", "\t\t\n", "\t\tif category_df[col].value_counts().count() <= 20:\n", "\t\t\tseaborn.catplot(x=col, data=category_df, alpha=0.7, kind='count')\n", "\t\t\tsave_bytes_image(image_list)\n", "\tres = {\n", "\t\t'output' : category_df.head(10).round(3).to_json(orient='table'),\n", "\t\t'result' : image_list,\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(category_df.head(10).round(3))\n", "\treturn res\n", "\n", "res = cat_count(self.current_df, self.intermediate_df, description, method)\n"], "id": "category-count", "metadata": {"input-attributes": {}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "correlation", "description": "human readable"}, "description": "Pairwise correlation between quantitative attributes", "code": ["def corr(loaded_dataset, intermediate_df, description, method):\n", "\tdf = loaded_dataset\n", "\tnumerical_df = df.select_dtypes(include='number')\n", "\tif (numerical_df.empty == True):\n", "\t\tres = {\n", "\t\t\t'result': \"Dataframe needs numeric values\",\n", "\t\t\t'output': \"Dataframe needs numeric values\",\n", "\t\t\t'description': \"Dataframe needs numeric values\",\n", "\t\t\t'type' : 'error'\n", "\t\t}\n", "\n", "\t\treturn res\n", "\t\n", "\tcorrelations = numerical_df.corr()\n", "\tres = {\n", "\t\t'result' : correlations.round(3).to_json(orient='table'),\n", "\t\t'output' : correlations.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\t\n", "\tintermediate_df.append(correlations.round(3))\n", "\treturn res\n", "res = corr(self.loaded_dataset, self.intermediate_df, description, method)"], "id": "corr", "metadata": {"input-attributes": {"method": [{"method": "string"}], "loaded-dataset": [{"Model": "string"}, {"MPG": "Number"}, {"Cylinders": "Number"}, {"Engine Disp": "Number"}, {"Horsepower": "Number"}, {"Weight": "Number"}, {"Accelerate": "Number"}, {"Year": "Number"}, {"Origin": "string"}]}, "output-attributes": {}}}, {"user-data": {"tags": ["statistical-summary"], "method": "group-statistics", "description": "human readable"}, "description": "Descriptive statistics of the dataset, such as mean, variance, minimum, and maximum.", "code": ["def des(loaded_dataset, intermediate_df, description, method): \n", "\tdescriptive_statistics = loaded_dataset.describe(include='all')\n", "\tres = {\n", "\t\t'result' : descriptive_statistics.round(3).to_json(orient='table'),\n", "\t\t'output' : descriptive_statistics.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : 'group-statistics'\n", "\t}\n", "\tintermediate_df.append(descriptive_statistics.round(3))\n", "\treturn res\n", "\n", "res = des(self.current_df, self.intermediate_df, description, method)"], "id": "50", "metadata": {"input-attributes": {"loaded-dataset": [{"Model": "string"}, {"MPG": "Number"}, {"Cylinders": "Number"}, {"Engine Disp": "Number"}, {"Horsepower": "Number"}, {"Weight": "Number"}, {"Accelerate": "Number"}, {"Year": "Number"}, {"Origin": "string"}]}, "output-attributes": {}}}, {"user-data": {"tags": ["data-formatting"], "method": "first10samples", "description": "human readable"}, "description": "Show the first 10 rows of the dataframe", "code": ["def firstTen(loaded_dataset, intermediate_df, description, method): \n", "\tdf = loaded_dataset\n", "\n", "\tsamples = df.head(10)\n", "\tres = {\n", "\t\t'result' : samples.round(3).to_json(orient='table'),\n", "\t\t'output' : samples.round(3).to_json(orient='table'),\n", "\t\t'description' : description,\n", "\t\t'type' : method\n", "\t}\n", "\tintermediate_df.append(samples.round(3))\n", "\treturn res\n", "\n", "res = firstTen(self.current_df, self.intermediate_df, description, method)\n"], "id": "firstTen", "metadata": {"input-attributes": {"method": [{"method": "string"}], "loaded-dataset": [{"Model": "string"}, {"MPG": "Number"}, {"Cylinders": "Number"}, {"Engine Disp": "Number"}, {"Horsepower": "Number"}, {"Weight": "Number"}, {"Accelerate": "Number"}, {"Year": "Number"}, {"Origin": "string"}]}, "output-attributes": {}}}]