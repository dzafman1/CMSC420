[
    {
        "user-data": {
            "method": "compute-covariance-matrix",
            "description": "human readable",
            "tags": [
                 ]
        },
        "id": "150",
        "description": "computes the covariance matrix",
        "code": [
            "def compute_covariance_matrix(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdata = {\"CovMeanDot\":[]}\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf_matrix = intermediate_df[-1]._get_numeric_data().values\n",
            "\telse:\n",
            "\t\tdf_matrix = loaded_dataset._get_numeric_data().values\n",

            "\tcovariance = np.cov(df_matrix)\n",
            "\tmean = np.mean(df_matrix, axis=0)\n",
            "\tinv = np.linalg.inv(covariance)\n",
            "\tdot = np.dot(np.dot(mean, inv), mean)\n",

            "\tdata[\"CovMeanDot\"].append(dot)\n",

            "\tres = {\n",
            "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data))\n",
            "\treturn res\n",
            "res = compute_covariance_matrix(self.current_df, self.intermediate_df, description, method)"

        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },

    {
        "user-data": {
            "method": "word-to-vec",
            "description": "human readable",
            "tags": [
                "text-data-formatting"
            ]
        },
        "id": "36",
        "description": "word2vec",
        "code": [
            "def word_to_vec(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf= loaded_dataset\n",            
            "\tres_df = calcWordVec(df)\n",
            "\tres = {\n",
            "\t\t'output': res_df.head(10).to_json(orient='table'),\n",
            "\t\t'result': res_df.head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(res_df.head(10))\n",
            "\treturn res\n",
            "res = word_to_vec(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "conditional-frequence-distribution",
            "description": "human readable",
            "tags": [
                "text-data-formatting"
            ]
        },
        "id": "183",
        "description": "conditional-frequence-distribution",
        "code": [
            "def conditional_frequence_distribution(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
            "\tres_df = calcConditionalFreqDist(df)\n",
            "res = {\n",
            "\t\t'output': df.head(10).to_json(orient='table'),\n",
            "\t\t'result': res_df.head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(df.head(10))\n",
            "\treturn res\n",
            "res = conditional_frequence_distribution(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "initialize-kmeans-cluster",
            "description": "human readable",
            "tags": [
                "statistical-sample"
            ]
        },
        "id": "162",
        "description": "initialize-kmeans-cluster",
        "code": [
            "def initialize_kmeans_cluster(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf= loaded_dataset\n",
            "\tres_df = initializeClustersForKmeans(df)\n",
            "\tres = {\n",
            "\t\t'output': df.head(10).to_json(orient='table'),\n",
            "\t\t'result': res_df.head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(df.head(10))\n",
            "\treturn res\n",
            "res = initialize_kmeans_cluster(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "decision-tree-regressor",
            "description": "human readable",
            "tags": [
                "train-model","test-model"
            ]
        },
        "id": "103",
        "description": "decision-tree-regressor",
        "code": [
            "def decision_tree_regressor(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
            "\tfrom sklearn.tree import DecisionTreeRegressor\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\ttree_reg1 = DecisionTreeRegressor(random_state=42)\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tX = df[quantitativeColumns[:-1]]\n",
            "\ty = df[[quantitativeColumns[-1]]]\n",

            "\ttree_reg1.fit(X, y)\n",
            "\ty_pred1 = tree_reg1.predict(X)\n",
            "\tout_df = X.copy()\n",
            "\tout_df[\"Expected-\"+quantitativeColumns[-1]] = y\n",
            "\tout_df[\"Predicted-\"+quantitativeColumns[-1]] = y_pred1\n",
            "\tres = {\n",
            "\t\t'output': out_df.head(10).to_json(orient='table'),\n",
            "\t\t'result': out_df.head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(out_df.head(10))\n",
            "\treturn res\n",
            "res = decision_tree_regressor(self.current_df, self.intermediate_df, description, method)"


        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "demo-mat-show",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "90",
        "description": "plot",
        "code": [
            "def demo_mat_show(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",

            "\timage_list = []\n",

            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tfrom sklearn.metrics import confusion_matrix\n",

            "\tdata = {'confusion': []}\n",

            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tyy_test = df[quantitativeColumns[0]].values.ravel()\n",
            "\tyy_pred = df[quantitativeColumns[1]].values.ravel()\n",
            
            "\tconfusion = confusion_matrix(yy_test, yy_pred)\n",
            
            "\tdata['confusion'].append(confusion)\n",

            "\tplt.matshow(confusion)\n",
            "\tplt.title('Confusion matrix')\n",
            "\tplt.gray()\n",
            "\tplt.ylabel('True label')\n",
            "\tplt.xlabel('Predicted label')\n",
            "\tsave_bytes_image(image_list)\n",

            "\tplt.clf()\n",
            
            "\tinvert_colors = np.ones(confusion.shape) * confusion.max()\n",
            "\tplt.matshow(invert_colors - confusion)\n",
            "\tplt.title('Confusion matrix')\n",
            "\tplt.gray()\n",
            "\tplt.ylabel('True label')\n",
            "\tplt.xlabel('Predicted label')\n",
            "\tsave_bytes_image(image_list)\n",
            "\tres = {\n",
            "\t\t'output': image_list\n",
            "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data).head(10))\n",
            "\treturn res\n", 
            "res = demo_mat_show(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "plot",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "43",
        "description": "plot",
        "code": [
            "def plot(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf_matrix = loaded_dataset\n",
           
            "\timage_list = []\n",
            "\timport matplotlib.gridspec as gridspec\n",
            "\tsamples = dict()\n",
            "\talt_df = df.select_dtypes(include='number')\n",
            "\th, w = alt_df.shape\n",
            "\tfor a in np.arange(h):\n",
            "\t\tsamples[a] = ((alt_df.iloc[[a]].values).ravel())[:4]\n",
            "\t\tif len(samples) >= 5:\n",
            "\t\t\tbreak\n",
            "\tfig = plt.figure(figsize=(10, 10))\n",
            "\tgs = gridspec.GridSpec(1, len(samples))\n",
            "\tgs.update(wspace=0.05, hspace=0.05)\n",
            "\tfor i, sample in samples.iteritems():\n",
            "\t\tax = plt.subplot(gs[i])\n",
            "\t\tplt.axis('off')\n",
            "\t\tax.set_xticklabels([])\n",
            "\t\tax.set_yticklabels([])\n",
            "\t\tax.set_aspect('equal')\n",
            "\t\tplt.imshow(sample.reshape(2, 2), cmap='Greys_r')\n",
            "\tsave_bytes_image(image_list)\n",
            "\tres = {\n",
            "\t\t'output': df.head(10).to_json(orient='table'),\n",
            "\t\t'result': image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(df.head(10))\n",
            "\treturn res\n",
            "res = plot(self.current_df, self.intermediate_df, description, method)"

        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "outer-join",
            "description": "human readable",
            "tags": [
                "data-organization"
            ]
        },
        "id": "32",
        "description": "outer join",
        "code": [
            "def outer_join(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf1 = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf1 = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf1 = loaded_dataset\n",
           
            "\tres = {\n",
            "\t\t'output': df1.head(10).to_json(orient='table'),\n",
            "\t\t'result': df1.head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(df1.head(10))\n",
            "\treturn res\n",
            "res = outer_join(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "quantitative-bar-plot",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "6",
        "description": "quantitative bar plot",
        "code": [
            "def quantitative_bar_plot(loaded_dataset, intermediate_df, description, method):\n", 
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\timage_list = []\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tx = df[quantitativeColumns[0]].values.ravel()\n",
            "\ty = df[[quantitativeColumns[1]]].values.ravel()\n",

            "\tplt.figure()\n",
            "\tplt.title(\"Plot Bar\")\n",
            "\tplt.bar(range(len(x)), y, align=\"center\")\n",
            "\tplt.xticks(range(len(x)), rotation=90)\n",
            "\tplt.xlim([-1, len(x)])\n",
            "\tsave_bytes_image(image_list)\n",
            "\tres = {\n",
            "\t\t'output': df.head(10).to_json(orient='table'),\n",
            "\t\t'result': image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(df.head(10))\n",
            "\treturn res\n", 
            "res = quantitative_bar_plot(self.current_df, self.intermediate_df, description, method)" 

        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "plot-via-limit",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "4",
        "description": "plot via limit",
        "code": [
            "def plot_via_limit(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",


            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1].select_dtypes(include='number')\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset.select_dtypes(include='number')\n",
           
            "\timage_list = []\n",
            "\tp_steps = 100\n",
            "\tv_steps = 100\n",
            "\tP = [item for sublist in df[df.columns[[0]]].values.tolist() for item in sublist]\n",
            "\tV = [item for sublist in df[df.columns[[1]]].values.tolist() for item in sublist]\n",

            "\tx = np.arange(-np.pi, np.pi, 2*np.pi/p_steps)\n",
            "\ty = []\n",
            "\tfor i in range(len(x)): y.append([])\n",
            "\tfor p, v in zip(P, V):\n",
            "\t\ti = int((p+np.pi)/(2*np.pi/p_steps))\n",
            "\t\ty[i].append(v)\n",
            "\tmeans = [ np.mean(np.array(vs)) for vs in y ]\n",
            "\tstds = [ np.std(np.array(vs)) for vs in y ]\n",

            "\tplt.plot(x, means)\n",

            "\tplt.plot([-2, -2], [-0.99, 0.99], 'k:', lw=1)\n",
            "\tplt.plot([2, 2], [-0.99, 0.99], 'k:', lw=1)\n",

            "\tplt.xlim([-np.pi, np.pi])\n",
            "\tplt.ylim([-1,1])\n",
            "\tplt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$', r'$-\\pi/2$', r'$0$', r'$+\\pi/2$', r'$+\\pi$'])\n",
            "\tplt.xlabel(r\"Phase [rad]\")\n",
            "\tplt.ylabel(r\"V mean\")\n",
            "\tsave_bytes_image(image_list)\n",
            "\tres = {\n",
            "\t\t'output': df.head(10).to_json(orient='table'),\n",
            "\t\t'result': image_list\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append( df.head(10))\n",
            "\treturn res\n",
            "res = plot_via_limit(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "probability-density-plot",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "83",
        "description": "plot of probability density function",
        "code": [
            "def probability_density_plot(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",

            
            "\timage_list = []\n",
            
            "\tfrom scipy.stats import chi2\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",

            "\tdata = {'rv':[], 'pdf':[]}\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tx = df[quantitativeColumns[0]].values.ravel()\n",
            "\tfor k in [1, 2]:\n",
            "\t\trv = chi2(k)\n",
            "\t\tpdf = rv.pdf(x)\n",

            "\t\tdata['rv'].append(rv)\n",
            "\t\tdata['pdf'].append(pdf)\n",

            "\t\tplt.plot(x, pdf, label=\"$k=%s$\" % k)\n",
            "\tplt.legend()\n",
            "\tplt.title(\"PDF ($\\chi^2_k$)\")\n",
            "\tsave_bytes_image(image_list)\n",
            "\toutput_df = pd.DataFrame(data)\n",
            "\tres = {\n",
            "\t\t'output': output_df.head(10).to_json(orient='table'),\n",
            "\t\t'result': image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(output_df.head(10))\n",
            "\treturn res\n", 
            "res = probability_density_plot(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "demo-log-space",
            "description": "human readable",
            "tags": [
                "data-generation"
            ]
        },
        "id": "72",
        "description": "demonstrate logarithm space",
        "code": [
            "def demo_log_space(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_datasetn",
           
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tfrom sklearn.model_selection import train_test_split\n",
            "\timport numpy as np\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tX = df[quantitativeColumns[:-1]]\n",
            "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n",
            "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
            "\tdata = {'svc__C': np.logspace(-3, 2, 6), 'svc__gamma': np.logspace(-3, 2, 6) / X_train.shape[0]}\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(data).head(10).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data).head(10))\n", 
            "\treturn res\n",
            "res = demo_log_space(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "unique-column-values",
            "description": "human readable",
            "tags": [
                "data-cleaning","data-formatting"
            ]
        },
        "id": "56",
        "description": "find unique columns values for each quantitative attributes",
        "code": [
            "def unique_column_values(loaded_dataset, intermediate_df, description, method):\n",
            "\ttest = {}\n",
            "\tdf = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\talt_df = df.select_dtypes(include='number')\n",
            "\tfor column in alt_df:\n",
            "\t\ttest[column] = alt_df.dropna().unique()\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(dict([ (k,pd.Series(test[k])) for k in test.keys() ])).head(10))\n",
            "\treturn res\n",
            "res = unique_column_values(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "extra-trees-classifier",
            "description": "human readable",
            "tags": [
                "train-model","test-model"
            ]
        },
        "id": "55",
        "description": "apply extra trees classifier to the data",
        "code": [
            "def extra_trees_classifier(loaded_dataset, intermediate_df, description, method):\n", 

            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tfrom sklearn.ensemble import ExtraTreesClassifier\n",
            "\tfrom sklearn.model_selection import cross_val_score\n",
            "\tfrom sklearn.model_selection import train_test_split\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tfrom sklearn.metrics import accuracy_score\n",
            "\tETC = ExtraTreesClassifier()\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tX = df[quantitativeColumns[:-1]]\n",
            "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n",
            "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
            "\tETC = ExtraTreesClassifier()\n",
            "\tETC.fit(X_train, y_train)\n",
            "\tprediction = ETC.predict(X_test)\n",
            "\tscores = cross_val_score(ETC,X_train,y_train,cv=2)\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(scores).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(scores).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(scores))\n",
            "\treturn res\n",
            "res = extra_trees_classifier(self.current_df, self.intermediate_df, description, method)"

        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "demo-hstack",
            "description": "human readable",
            "tags": [
                "data-organizing"
            ]
        },
        "id": "33",
        "description": "demonstrate the operation of hstack in numpy/scipy",
        "code": [
            "def demo_hstack(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\timport numpy as np\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tx = df[quantitativeColumns[0]].values.ravel()\n",
            "\ty = df[quantitativeColumns[1]].values.ravel()\n",
            "\tx1 = 1 / x\n",
            "\ty1 = 1 / y\n",
            "\tx2, y2 = np.dot(np.random.uniform(size=(2, 2)), np.random.normal(size=(2, len(x))))\n",
            "\tu = np.hstack([x1, x2])\n",
            "\tv = np.hstack([y1, y2])\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame([u, v]).head(10).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame([u, v]).head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame([u, v]).head(10))\n",
            "\treturn res\n",
            "res = demo_hstack(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "decision-tree-classifier",
            "description": "human readable",
            "tags": [
                "train-model","test-model"
            ]
        },
        "id": "27",
        "description": "fit the dataset into decision tree classifier",
        "code": [
            "def decision_tree_classifier(loaded_dataset, intermediate_df, description, method):\n", 
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tfrom sklearn.tree import DecisionTreeClassifier\n",
            "\tfrom sklearn.model_selection import train_test_split\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tfrom sklearn.metrics import accuracy_score\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tX = df[quantitativeColumns[:-1]]\n",
            "\ty = df[[quantitativeColumns[-1]]].values.ravel()\n",
            "\tclassifier = DecisionTreeClassifier()\n",
            "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
            "\tclassifier.fit(X_train, y_train)\n",
            "\tprediction = classifier.predict(X_test)\n",
            "\tdata = {'accuracyScore': []}\n",
            "\tdata['accuracyScore'].append(accuracy_score(y_test, prediction, normalize=False))\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(data).head(10).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(data).head(10).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data).head(10))\n",
            "\treturn res\n", 
            "res = decision_tree_classifier(self.current_df, self.intermediate_df, description, method)"

        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "compute-percentiles-range",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "134",
        "description": "Compute range (in percentage) for interval 5% - 95%",
        "code": [
            "def compute_percentiles_range(loaded_dataset, intermediate_df, description, method):\n", 
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tlowerPercentile = 5\n",
            "\tupperPercentile = 95\n",
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
            
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tdata = {\"Percentile\"+str(lowerPercentile):[],\"Percentile\"+str(upperPercentile):[],\"columnName\":quantitativeColumns}\n",
            "\tfor c in quantitativeColumns:\n",
            "\t\tdata[\"Percentile\"+str(lowerPercentile)].append(np.percentile(df[[c]],lowerPercentile))\n",
            "\t\tdata[\"Percentile\"+str(upperPercentile)].append(np.percentile(df[[c]],upperPercentile))\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data))\n",
            "\treturn res\n",
            "res = compute_percentiles_range(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "random-forest-classifier",
            "description": "human readable",
            "tags": [
                "train-model","test-model"
            ]
        },
        "id": "30",
        "description": "Test random forest classifier",
        "code": [
            "def random_forest_classifier(loaded_dataset, intermediate_df, description, method):\n", 
            "\tfrom sklearn.ensemble import RandomForestClassifier\n",
            "\tfrom sklearn.model_selection import cross_val_score\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tdf = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1].select_dtypes(include='number')\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset.select_dtypes(include='number')\n",
           
            "\tforest = RandomForestClassifier(n_estimators=100, n_jobs=-1,random_state=17)\n",
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tX_train = df[quantitativeColumns[:-1]]\n",
            "\ty_train = df[[quantitativeColumns[-1]]].values.ravel()\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n", 
            "\tintermediate_df.append(pd.DataFrame(cross_val_score(forest,X_train,y_train,cv=5)))\n",
            "\treturn res\n",
            "res = random_forest_classifier(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "eval-model-predictions",
            "description": "human readable",
            "tags": [
                "train-model"
            ]
        },
        "id": "18",
        "description": "Evaluate the prediction of linear regression",
        "code": [
            "def eval_model_predictions(loaded_dataset, intermediate_df, description, method):\n",
            
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1].select_dtypes(include='number')\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset.select_dtypes(include='number')\n",

            "\tpredictions = df.iloc[:,-1].values\n",
            "\tlabels = df.iloc[:,-2].values\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(np.equal(predictions,labels)).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(np.equal(predictions,labels)).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(np.equal(predictions,labels)))\n",
            "\treturn res\n",
            "res = eval_model_predictions(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "test-linear-regression",
            "description": "human readable",
            "tags": [
                "train-model","test-model"
            ]
        },
        "id": "113",
        "description": "Evaluate the prediction of linear regression",
        "code": [
            "def test_linear_regression(loaded_datset, intermediate_df, description, method):\n", 
            "\tfrom sklearn.linear_model import LinearRegression\n",
            "\tfrom sklearn.model_selection import cross_val_score\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tlinear_regression = LinearRegression()\n",
            "\tdf = None\n", 
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tquantitativeColumns = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tdata = df[quantitativeColumns[:-1]]\n",
            "\ttarget = df[[quantitativeColumns[-1]]].values\n",
            "\tres = {\n",
            "\t'output': pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)).to_json(orient='table'),\n",
            "\t'result': pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)).to_json(orient='table'),\n",
            "\t'description' : description,\n",
            "\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(cross_val_score(linear_regression, data, target, cv=10)))\n",
            "\treturn res\n",
            "res = test_linear_regression(self.current_df, self.intermediate_df, description, method"
            
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "matrix-norm",
            "description": "human readable",
            "tags": [
                "data-formatting"
            ]
        },
        "id": "10",
        "description": "Compute column norm for each quantitative column",
        "code": [
            "def matrix_norm(loaded_dataset, intermediate_df, description, method):\n", 
            "\timport numpy.linalg as LA\n",
            "\tfrom pandas.api.types import is_numeric_dtype\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnCols = [c for c in list(df) if is_numeric_dtype(df[c])]\n",
            "\tdata = {\"columnName\":[],\"NumpyLinalgNorm\":[]}\n", 
            "\tfor nc in nCols:\n",
            "\t\tdata[\"columnName\"].append(nc)\n",
            "\t\tdata[\"NumpyLinalgNorm\"].append(LA.norm(df[[nc]].values))\n",
            "\tres = {\n",
            "\t\t'output': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'result': pd.DataFrame(data).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type': method\n",
            "\t}\n",
            "\tintermediate_df.append(pd.DataFrame(data))\n",
            "\treturn res\n",
            "res = matrix_norm(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "bootstrap",
            "description": "human readable",
            "tags": [
                "statistical-sample"
            ]
        },
        "id": "bootstrap",
        "description": "Resampling technique used to estimate statistics on a population by sampling a dataset with replacement",
        "code": [
            "def bootstrap(loaded_dataset, intermediate_df, description, method):\n",
            "\tcurrent_df = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tcurrent_df = intermediate_df[-1].select_dtypes('number')\n",
            "\telse:\n",
            "\t\tcurrent_df = loaded_dataset.select_dtypes('number')\n",
           
            "\tfrom sklearn.utils import resample\n",
            "\tmean = []\n",
            "\tstatistics = pd.DataFrame()\n",
            "\tfor i in range(0, 1000):\n",
            "\t\tboot = resample(current_df, replace=True, n_samples=int(0.5 * len(current_df.index)))\n",
            "\t\tmean.append(boot.mean().to_dict())\n", 
            "\tfor key in mean[0]:\n",
            "\t\tcurr_list = [item[key] for item in mean]\n",
            "\t\talpha = 0.95\n",
            "\t\tp = (1.0-alpha) * 100\n",
            "\t\tlower = np.percentile(curr_list, p)\n",
            "\t\tp = alpha * 100\n",
            "\t\tupper = np.percentile(curr_list, p)\n",
            "\t\tstatistics[key] = [str(round(lower, 3)) + '-' + str(round(upper, 3))]\n", 
            "\tres = {\n",
            "\t\t'output' : current_df.head(10).round(3).to_json(orient='table'),\n",
            "\t\t'result' : statistics.to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n",
            "\t}\n",
            "\tintermediate_df.append(current_df.head(10).round(3))",
            "\treturn res\n",
            "res = bootstrap(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        
        "user-data": {
            "method": "ANOVA-Variance-Analysis",
            "description": "human readable",
            "tags": [
                "statistical-test"
            ]
        },
        "id": "ANOVA-Variance-Analysis",
        "description": "One sample test of Analysis of Variance on quantitative attributes, grouped by categorical attributes",
        "code": [
            "def anova_variance(loaded_dataset, intermediate_df, description, method):\n", 
            "\tcurrent_df = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tcurrent_df = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tcurrent_df = loaded_dataset\n",

            "\tcategory_cols = current_df.select_dtypes(include='object').columns\n",
            "\tnumerical_cols = current_df.select_dtypes(include='number').columns\n",
            "\tres_df = pd.DataFrame(columns=category_cols, index=numerical_cols)\n",
            "\tfor num_col in numerical_cols:\n", 
            "\t\tfor cat_col in category_cols:\n",
            "\t\t\tif current_df[cat_col].value_counts().count() <= 10:\n", 
            "\t\t\t\tgroups = current_df.groupby(cat_col).groups.keys()\n", 
            "\t\t\t\tprint groups\n\t\t\t\tprint current_df[current_df[cat_col] == groups[0]][num_col]\n",
            "\t\t\t\tif len(groups) >= 3:\n", 
            "\t\t\t\t\tf_val, p_val = stats.f_oneway(current_df[current_df[cat_col] == groups[0]][num_col], current_df[current_df[cat_col] == groups[1]][num_col], current_df[current_df[cat_col] == groups[2]][num_col])\n",
            "\t\t\t\t\tres_df[cat_col][num_col] = p_val\n",
            "\tres = {\n",
            "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", 
            "\t\t'result' : res_df.round(3).to_json(orient='table'),\n", 
            "'description' : description,\n\t\t'type' : method\n", 
            "\t}\n", 
            "\tintermediate_df.append(res_df.round(3))",
            "\treturn res\n",
            "res = anova_variance(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "drop-NaN-rows",
            "description": "human readable",
            "tags": [
                "data-cleaning"
            ]
        },
        "id": "drop-NaN-rows",
        "description": "Remove rows with NaN values in any entry",
        "code": [
            "def drop_rows(loaded_dataset, intermediate_df, description, method):\n", 
            "\tnew_df = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tnew_df = intermediate_df[-1].dropna()\n",
            "\telse:\n",
            "\t\tnew_df = loaded_dataset.dropna()\n",
           
            "\tres = {\n", 
            "\t\t'output' : new_df.head(10).round(3).to_json(orient='table'),\n", 
            "\t\t'result' : new_df.describe().round(3).to_json(orient='table'),\n", 
            "\t\t'description' : description,\n\t\t'type' : method\n",
            "\t}\n",
            "\tintermediate_df.append(new_df.head(10).round(3))\n", 
            "\treturn res\n",
            "res = drop_rows(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "ranksum-test",
            "description": "human readable",
            "tags": [
                "statistical-test"
            ]
        },
        "id": "ranksum-test",
        "description": "Useful test to determine if two distributions are significantly different or not. \n Unlike the t-test, the RankSum test does not assume that the data are normally distributed.",
        "code": [
            "def rank_sum(loaded_dataset, intermediate_df, description, method):\n", 
            "\tcurrent_df = None\n",
            
            "\tif len(intermediate_df) != 0:\n",
            "\t\tcurrent_df = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tcurrent_df = loaded_dataset\n",
           
            "\tnumerical_df = current_df.select_dtypes(include='number')\n", 
            "\tres_df = pd.DataFrame(columns=(numerical_df.columns), index=(numerical_df.columns))\n",
            "\tfor col1, col2 in itertools.combinations(numerical_df, 2):\n",
            "\t\tz_stat, p_val = stats.ranksums(numerical_df[col1], numerical_df[col2])\n",
            "\t\tres_df[col1][col2] = p_val\n",
            "\t\tres_df[col2][col1] = p_val\n", 
            "\tres = {\n", 
            "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n", 
            "\t\t'result' : res_df.round(3).to_json(orient='table'),\n", 
            "\t\t'description' : description,\n\t\t'type' : method\n", 
            "\t}\n",
            "\tintermediate_df.append(res_df.round(3))", 
            "\treturn res\n",
            "res = rank_sum(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "variance",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "variance",
        "description": "Variance of quantitative attributes in the dataset",
        "code": [
            "def variance(loaded_dataset, description, method):\n", 
            "\tnew_df = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tnew_df = intermediate_df[-1].var()\n",
            "\telse:\n",
            "\t\tdf_matrix = loaded_dataset.var()\n",
           
            "\tres = {\n", 
            "\t\t'output' : loaded_dataset.head(10).round(3).to_json(orient='table'),\n",
            "\t\t'result' : new_df.round(3).to_json(orient='table'),\n", 
            "\t\t'description' : description,\n\t\t'type' : method\n", 
            "\t}\n", 
            "\tself.intermediate_df.append(new_df.round(3))\n",
            "\treturn res\n",
            "res = variance(self.current_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "mean",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "mean",
        "description": "Average of quantitative attributes in the dataset",
        "code": [
            "def mean(loaded_dataset, intermediate_df, description, method):\n",
            "\tnew_df = pd.DataFrame(loaded_dataset.mean(), columns=['mean'])\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tnew_df = pd.DataFrame(intermediate_df[-1].mean(), columns=['mean'])\n",
            "\telse:\n",
            "\t\tnew_df = pd.DataFrame(loaded_dataset.mean(), columns=['mean'])\n",
           
            "\tprint(new_df)\n", 
            "\tres = {\n", 
            "\t\t'output' : self.current_df.head(10).round(3).to_json(orient='table'),\n",
            "\t\t'result' : new_df.round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n\t\t'type' : method\n",
            "\t}\n",
            "\tintermediate_df.append(new_df.round(3))\n",
            "\treturn res\n",
            "res = mean(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },

    {
        "user-data": {
            "method": "predict-test",
            "description": "human readable",
            "tags": [
                "test-model"
            ]
        },
        "id": "predict-test",
        "description": "Evaluate the model on the test set.\nthe output would show the comparison of predicted and actual values. ",
        "code": [
            "def predict_test(loaded_dataset, description, method):\n",
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\treg = df[-1]\n", 
            "\tX_train, X_test, y_train, y_test = df[-2]\n",
            "\ty_predict = reg.predict(X_test)\n", 
            "\tnew_df = pd.DataFrame()\n",
            "\tnew_df['predicted'] = y_predict\n",
            "\tnew_df['actual'] = list(y_test)\n",
            "\tres = {\n", 
            "\t\t'output' : new_df.head(10).round(3).to_json(orient='table'),\n", 
            "\t\t'result' : \"predicted vs. actual test done, see Output Data Frame Tab.\",\n",
            "\t\t'description' : description,\n\t\t'type' : method\n",
            "\t}\n", 
            "\tintermediate_df.append(new_df.head(10).round(3))\n",
            "\treturn res\n",
            "res = predict_test(self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "fit-decision-tree",
            "description": "human readable",
            "tags": [
                "train-model"
            ]
        },
        "id": "fit-decision-tree",
        "description": "Fit a decision tree model with current training dataset",
        "code": [
            "def fit_decision_tree(loaded_dataset, intermediate_df, description, method):\n",
            "\t df = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tX_train, X_test, y_train, y_test = df\n",
            "\treg = fit_model(X_train, y_train)\n",
            "\tres = {\n", 
            "\t\t'output' : y_train.head(10).round(3).to_json(orient='table'),\n",
            "\t\t'result' : \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']),\n",
            "\t\t'description' : description,\n\t\t'type' : method\n",
            "\t}\n",
            "\tintermediate_df.append(y_train.head(10).round(3))\n",
            "\treturn res\n",
            "res = fit_decision_tree(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },

    {
        "user-data": {
            "method": "shuffle-split",
            "description": "human readable",
            "tags": [
                "data-organizing"
            ]
        },
        "id": "shuffle-split",
        "description": "Shuffle and split the dataset into training and testing.\nOutput shows the 3 features randomly selected for the model.",
        "code": [
            "def shuffle_split(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_df = df.select_dtypes(include='number')\n",
            "\tfeatures = numerical_df[numerical_df.columns[0:3]]\n",
            "\tpredicted_variables = numerical_df[numerical_df.columns[-1]]\n",
            "\tfrom sklearn.model_selection import train_test_split\n",
            "\tX_train, X_test, y_train, y_test = train_test_split(features, predicted_variables, test_size=0.2,random_state=100)\n",
            "\tnew_df = (X_train, X_test, y_train, y_test)\n",
            "\tintermediate_df.append(new_df)\n", 
            "\tres = {\n",
            "\t\t'output' : X_train.head(10).round(3).to_json(orient=\"table\"),\n",
            "\t\t'result' : \"split into training and testing set\",\n",
            "\t\t'description' : description,\n\t\t'type' : method\n",
            "\t}\n",
            "\tintermediate_df.append(X_train.head(10).round(3))\n",
            "\treturn res\n",
            "res = shuffle_split(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "numerical-boxplot",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "numerical-boxplot",
        "description": "Box plot that shows distribution of quantitative attributes with variance",
        "code": [
            "def num_boxplot(loaded_dataset, description, method):\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_cols = df.select_dtypes(include='number').columns\n",
            "\timage_list = []\n",
            "\tfor num_var in numerical_cols:\n",
            "\t\tplt.clf()\n\t\tax = seaborn.boxplot(y=num_var, data=df)\n",
            "\t\tplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n",
            "\t\tplt.xticks(rotation=45)\n",
            "\t\tsave_bytes_image(image_list)\n",
            "\t\tif len(image_list) >= 5:\n\t\t\tbreak\n",
            "\tres = {\n\t\t'output' : df.select_dtypes(include='number').head(10).round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(df.select_dtypes(include='number').head(10).round(3))\n",
            "\treturn res\n",
            "res = num_boxplot(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "top5categories",
            "description": "human readable",
            "tags": [
                "data-formatting"
            ]
        },
        "id": "top5categories",
        "description": "TODO",
        "code": [
            "def top5cat(loaded_dataset, description, method):\n",
            "\tcategory_df = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tcategory_df = intermediate_df[-1].select_dtypes(include='object')\n",
            "\telse:\n",
            "\t\tcategory_df = loaded_dataset.select_dtypes(include='object')\n",
           
            "\tfor col in category_df:\n",
            "\t\tsamples = category_df[col].value_counts().head(5)\n",
            "\t\tres = {\n\t\t\t'output' : samples.round(3).to_json(orient='table'),",
            "\n\t\t\t'result' :samples.round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t\t'type' : method\n\t\t}\n\t\tbreak\n",
            "\tintermediate_df.append(samples.round(3))\n",
            "\treturn res\n",
            "res = top5cat(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "drop-NaN-columns",
            "description": "human readable",
            "tags": [
                "data-cleaning"
            ]
        },
        "id": "48",
        "description": "Drop columns with more than 30% NaN entries",
        "code": [
            "def drop_cols(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf = None\n",
            
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tdropped_columns = []\n",
            "\tdf2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\n",
            "\tfor c in df.columns:\n",
            "\t\tif c not in df2.columns:\n",
            "\t\t\tdropped_columns.append(c)\n",
            "\tloaded_dataset = df2\n",
            "\tres = {\n\t\t'output' : df.describe().round(3).to_json(orient='table'),",
            "\n\t\t'result' : df.describe().round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(df.describe().round(3))\n",
            "\treturn res\n",
            "res = drop_cols(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "distribution-quantitative-category",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "distribution-quantitative-category",
        "description": "Distribution plot between quantitative and categorical attributes",
        "code": [
            "def dist_quant_category(loaded_dataset, description, method):\n",
            "\timage_list = []\n",
            "\tclean_dataset = pd.DataFrame()\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tfor col in loaded_dataset.columns:\n",
            "\t\tif df[col].dtype == 'object' or df[col].value_counts().count() <= 20:\n",
            "\t\t\tclean_dataset[col] = df[col].astype('category')\n",
            "\t\telse:\n",
            "\t\t\tclean_dataset[col] = df[col]\n",
            "\tnumerical_cols = clean_dataset.select_dtypes(include='number').columns\n",
            "\tcategory_cols = clean_dataset.select_dtypes(include='category').columns\n",
            "\tcount = 0\n\tfor col1, col2 in zip(numerical_cols, category_cols):\n",
            "\t\tif clean_dataset[col2].value_counts().count() <= 10:\n",
            "\t\t\tseaborn.catplot(col2, col1, data=clean_dataset)\n",
            "\t\t\tsave_bytes_image(image_list)\n\t\t\tcount+=1\n",
            "\t\t\tif count >= 5:\n",
            "\t\t\t\tbreak\n",
            "\tres = {\n\t\t'output' : clean_dataset.head(10).round(3).to_json(orient='table'),\n",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(clean_dataset.head(10).round(3)\n",
            "\treturn res\n",
            "res = dist_quant_category(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "distribution-two-categories",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "distribution-two-categories",
        "description": "Distribution across two categorical attributes",
        "code": [
            "def dist_two_categories(loaded_dataset, description, method):\n",
            "\timage_list = []\n\tclean_dataset = pd.DataFrame()\n",

            "\tdf = None\n", 
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tfor col in df.columns:\n",
            "\t\tif df[col].dtype == 'object' or df[col].value_counts().count() <= 20:\n",
            "\t\t\tclean_dataset[col] = df[col].astype('category')\n",
            "\tcategory_df = clean_dataset.select_dtypes(include='category')\n\tcount = 0\n",
            "\tfor col1, col2 in itertools.combinations(category_df.columns, 2):\n",
            "\t\tif category_df[col1].value_counts().count() <= 10 and \\\n",
            "\t\t\tcategory_df[col2].value_counts().count() <= 5:\n\t\t\tseaborn.catplot(col1, data=category_df, hue=col2, kind='count')\n",
            "\t\t\tsave_bytes_image(image_list)\n\t\t\tcount += 1\n\t\t\tif count >= 5:\n\t\t\t\tbreak\n",
            "\tres = {\n\t\t 'output' : category_df.head(10).round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(category_df.head(10).round(3))\n",
            "\treturn res\n",
            "res = dist_two_categories(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "category-boxplot",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "category-boxplot",
        "description": "Boxplot for categorical attributes",
        "code": [
            "def cat_boxplot(loaded_dataset, description, method):\n",
            "\t df = None\n",
            
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_cols = df.select_dtypes(include='number').columns\n",
            "\tcategory_cols = df.select_dtypes(include='object').columns\n",
            "\timage_list = []\n",
            "\tfor cat_var in category_cols:\n",
            "\t\tif df[cat_var].value_counts().count() <= 5:\n",
            "\t\t\tfor num_var in numerical_cols:\n",
            "\t\t\t\tplt.clf()\n",
            "\t\t\t\tax = seaborn.boxplot(x=cat_var, y=num_var, data=df)\n",
            "\t\t\t\tplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n",
            "\t\t\t\tplt.xticks(rotation=45)\n",
            "\t\t\t\tsave_bytes_image(image_list)\n",
            "\t\t\t\tif len(image_list) >= 5:\n",
            "\t\t\t\t\tbreak\n",
            "\t\tif len(image_list) >= 5:\n",
            "\t\t\tbreak\n",
            "\tres = {\n\t\t'output' : df.head(10).round(3).to_json(orient='table'),\n",
            "\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(df.head(10).round(3))\n",
            "\treturn res\n",
            "res = cat_boxplot(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "correlation-heatmap",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "correlation-heatmap",
        "description": "Correlation heatmap across quantitative attributes",
        "code": [
            "def corr_heatmap(loaded_dataset, description, method):\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tcorr = df.select_dtypes(include='number').corr()\n",
            "\timage_list = []\n\tplt.clf()\n\tseaborn.heatmap(corr, cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,annot=True, annot_kws={\"size\": 8}, square=True)\n",
            "\tsave_bytes_image(image_list)\n",
            "\tres = {\n\t\t'output' : corr.round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(corr.round(3))\n",
            "\treturn res\n",
            "res = corr_heatmap(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "stack-facetgrid",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "stack-facetgrid",
        "description": "Show how the distribution of quantitative attributes varies for different categorical attributes",
        "code": [
            "def stack_ftgrid(loaded_dataset, description, method):\n",
            "\tdf = None\n",

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_cols = df.select_dtypes(include='number').columns\n",
            "\tcategory_cols = df.select_dtypes(include='object').columns\n",
            "\timage_list = []\n",
            "\tfor cat_var in category_cols:\n",
            "\t\tif df[cat_var].value_counts().count() <= 5:\n",
            "\t\t\tfor num_var in numerical_cols:\n",
            "\t\t\t\tplt.clf()\n\t\t\t\tfig = seaborn.FacetGrid(df,hue=cat_var)\n",
            "\t\t\t\tfig.map(seaborn.kdeplot,num_var,shade=True)\n\t\t\t\toldest = df[num_var].max()\n",
            "\t\t\t\tfig.set(xlim=(0, oldest))\n\t\t\t\tfig.add_legend()\n",
            "\t\t\t\tsave_bytes_image(image_list)\n",
            "\t\t\t\tif len(image_list) >= 5:\n",
            "\t\t\t\t\tbreak\n",
            "\tres = {\n\t\t'output' : df.head(10).round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(df.head(10).round(3))\n",
            "\treturn res\n",
            "res = stack_ftgrid(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "scatterplot-regression",
            "description": "human readable",
            "tags": [
                "visualization"
            ]
        },
        "id": "scatterplot-regression",
        "description": "Scatterplot with two quantitative attributes and corresponding regression line",
        "code": [
            "def scatterplot_regression(loaded_dataset, description, method):\n",
            "\tdf = None\n", 

            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_df = df.select_dtypes(include='number')\n",
            "\timage_list = []\n\tcount = 0\n",
            "\tfor col1, col2 in itertools.combinations(numerical_df, 2):\n",
            "\t\tplt.clf()\n",
            "\t\tseaborn.regplot(df[col1], df[col2])\n",
            "\t\tsave_bytes_image(image_list)\n",
            "\t\tcount+=1\n",
            "\t\tif count >= 5:\n",
            "\t\t\tbreak\n",
            "\tres = {\n\t\t'output' : numerical_df.head(10).round(3).to_json(orient='table'),\n",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(numerical_df.head(10).round(3))\n",
            "\treturn res\n",
            "res = scatterplot_regression(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "distribution-quantitative",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "63",
        "description": "Bin the quantitative attributes and show the distribution within each bin",
        "code": [
            "def dist_num(loaded_dataset, description, method):\n",
            "\timage_list = []\n",
            "\tdf = None\n",
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_df = df.select_dtypes(include='number')\n",
            "\tcount = 0\n",
            "\tfor col in numerical_df:\n",
            "\t\tfig, ax = plt.subplots()\n\t\tax.hist(numerical_df[col])\n\t\tplt.xlabel(col)\n\t\tplt.ylabel(\"Dist\")\n\t\tplt.title('Histogram of ' + col)\n",
            "\t\tsave_bytes_image(image_list)\n\t\tcount += 1\n",
            "\t\tif count >= 5:\n\t\t\tbreak\n",
            "\tres = {\n\t\t\t'output' : numerical_df.head(10).round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(numerical_df.head(10).round(3))\n",
            "\treturn res\n",
            "res = dist_num(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "category-count",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "category-count",
        "description": "The distribution of categorical attributes across different values",
        "code": [
            "def cat_count(loaded_dataset, description, method):\n",
            "\tdf = None\n", 
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tcategory_df = df.select_dtypes(include='object')\n",
            "\timage_list = []\n",
            "\tfor col in category_df:\n",
            "\t\tif category_df[col].value_counts().count() <= 20:\n",
            "\t\t\tseaborn.catplot(x=col, data=category_df, alpha=0.7, kind='count')\n",
            "\t\t\tsave_bytes_image(image_list)\n",
            "\tres = {\n\t\t\t'output' : category_df.head(10).round(3).to_json(orient='table'),",
            "\n\t\t'result' : image_list,\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(category_df.head(10).round(3))\n",
            "\treturn res\n",
            "res = cat_count(self.current_df, description, method)\n",
            "self.intermediate_df.append(self.current_df)"
        ],
        "metadata": {
            "input-attributes": {},
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "correlation",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "corr",
        "description": "Pairwise correlation between quantitative attributes",
        "code": [
            "def corr(loaded_dataset, intermediate_df, description, method):\n",
            "\tdf = None\n", 
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tnumerical_df = df.select_dtypes(include='number')\n",
            "\tcorrelations = numerical_df.corr()\n",
            "\tres = {\n\t\t'result' : correlations.round(3).to_json(orient='table'),\n",
            "\t\t'output' : correlations.round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(correlations.round(3))\n",
            "\treturn res\n",
            "res = corr(self.loaded_dataset, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {
                "loaded-dataset": [
                    {
                        "Model": "string"
                    },
                    {
                        "MPG": "Number"
                    },
                    {
                        "Cylinders": "Number"
                    },
                    {
                        "Engine Disp": "Number"
                    },
                    {
                        "Horsepower": "Number"
                    },
                    {
                        "Weight": "Number"
                    },
                    {
                        "Accelerate": "Number"
                    },
                    {
                        "Year": "Number"
                    },
                    {
                        "Origin": "string"
                    }
                ],
                "method": [
                    {
                        "method": "string"
                    }
                ]
            },
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "group-statistics",
            "description": "human readable",
            "tags": [
                "statistical-summary"
            ]
        },
        "id": "50",
        "description": "Descriptive statistics of the dataset, such as mean, variance, minimum, and maximum.",
        "code": [
            "def des(loaded_dataset, intermediate_df, description): \n\tdescriptive_statistics = loaded_dataset.describe(include='all')\n",
            "\tres = {\n\t\t'result' : descriptive_statistics.round(3).to_json(orient='table'),\n",
            "\t\t'output' : descriptive_statistics.round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : 'group-statistics'\n\t}\n",
            "\tintermediate_df.append(descriptive_statistics.round(3))\n",
            "\treturn res\n",
            "res = des(self.current_df, self.intermediate_df, description)"
        ],
        "metadata": {
            "input-attributes": {
                "loaded-dataset": [
                    {
                        "Model": "string"
                    },
                    {
                        "MPG": "Number"
                    },
                    {
                        "Cylinders": "Number"
                    },
                    {
                        "Engine Disp": "Number"
                    },
                    {
                        "Horsepower": "Number"
                    },
                    {
                        "Weight": "Number"
                    },
                    {
                        "Accelerate": "Number"
                    },
                    {
                        "Year": "Number"
                    },
                    {
                        "Origin": "string"
                    }
                ]
            },
            "output-attributes": {}
        }
    },
    {
        "user-data": {
            "method": "first10samples",
            "description": "human readable",
            "tags": [
                "data-formatting"
            ]
        },
        "id": "firstTen",
        "description": "Show the first 10 rows of the dataframe",
        "code": [
            "def firstTen(loaded_dataset, intermediate_df, description, method): \n",
            "\tdf = None\n", 
            "\tif len(intermediate_df) != 0:\n",
            "\t\tdf = intermediate_df[-1]\n",
            "\telse:\n",
            "\t\tdf = loaded_dataset\n",
           
            "\tsamples = df.head(10)\n",
            "\tres = {\n\t\t'result' : samples.round(3).to_json(orient='table'),\n",
            "\t\t'output' : samples.round(3).to_json(orient='table'),\n",
            "\t\t'description' : description,\n",
            "\t\t'type' : method\n\t}\n",
            "\tintermediate_df.append(samples.round(3))\n",
            "\treturn res\n",
            "res = firstTen(self.current_df, self.intermediate_df, description, method)"
        ],
        "metadata": {
            "input-attributes": {
                "loaded-dataset": [
                    {
                        "Model": "string"
                    },
                    {
                        "MPG": "Number"
                    },
                    {
                        "Cylinders": "Number"
                    },
                    {
                        "Engine Disp": "Number"
                    },
                    {
                        "Horsepower": "Number"
                    },
                    {
                        "Weight": "Number"
                    },
                    {
                        "Accelerate": "Number"
                    },
                    {
                        "Year": "Number"
                    },
                    {
                        "Origin": "string"
                    }
                ],
                "method": [
                    {
                        "method": "string"
                    }
                ]
            },
            "output-attributes": {}
        }
    }
]
